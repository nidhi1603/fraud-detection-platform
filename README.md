# Real-Time Fraud Detection Platform

> **Status:** ğŸš§ Project in development - Started October 2025

## What I'm Building

A production-grade fraud detection system that processes financial transactions in real-time using machine learning and streaming data pipelines.

## Why This Project?

This project demonstrates my skills in:
- Real-time data engineering
- Machine learning for classification
- Distributed systems architecture
- Production-level software development

## Planned Tech Stack

**Data Streaming:**
- Apache Kafka (message broker)
- Apache Flink (stream processing)

**Databases:**
- ClickHouse (real-time analytics)
- Neo4j (fraud pattern detection)
- PostgreSQL (transaction storage)

**Machine Learning:**
- Python, scikit-learn, XGBoost
- Fraud detection classification

**Infrastructure:**
- Docker & Docker Compose
- AWS (deployment)
- Grafana & Prometheus (monitoring)

## Project Phases

### Phase 1: Environment Setup âœ… (Current)
- [x] Create project structure
- [x] Set up Git version control
- [ ] Configure development environment
- [ ] Set up Docker containers

### Phase 2: Data Generation (Week 1-2)
- [ ] Build fake transaction generator
- [ ] Create realistic fraud patterns
- [ ] Test data pipeline

### Phase 3: Streaming Pipeline (Week 2-3)
- [ ] Implement Kafka producer
- [ ] Implement Kafka consumer
- [ ] Set up data processing

### Phase 4: Machine Learning (Week 3-4)
- [ ] Train fraud detection model
- [ ] Integrate ML with streaming
- [ ] Optimize model performance

### Phase 5: Analytics & Visualization (Week 4-5)
- [ ] Set up ClickHouse database
- [ ] Create Grafana dashboards
- [ ] Add real-time alerting

### Phase 6: Graph Analysis (Week 5-6)
- [ ] Implement Neo4j integration
- [ ] Detect fraud rings and patterns
- [ ] Visualize transaction networks

### Phase 7: Production Deployment (Week 6-7)
- [ ] Containerize all services
- [ ] Deploy to AWS
- [ ] Set up CI/CD pipeline
- [ ] Write comprehensive documentation

## Repository Structure
```
fraud-detection-platform/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ data_generator/    # Transaction data generator
â”‚   â”œâ”€â”€ streaming/         # Kafka producer/consumer
â”‚   â”œâ”€â”€ ml_model/          # Machine learning models
â”‚   â””â”€â”€ monitoring/        # Metrics and monitoring
â”œâ”€â”€ config/                # Configuration files
â”œâ”€â”€ tests/                 # Test files
â”œâ”€â”€ notebooks/             # Jupyter notebooks for exploration
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ data/                  # Data files (gitignored)
â””â”€â”€ README.md             # This file
```

## Current Progress

**Week 1 - Day 1:**
- âœ… Initialized project repository
- âœ… Created project structure
- âœ… Set up Git version control
- â³ Next: Environment setup with Docker

## Setup Instructions

Coming soon - will be updated as components are built.

## Author

**Nidhi Rajani**
- MS Data Science @ University at Buffalo (Expected May 2026)
- Former Data Analyst @ Flipkart (Walmart)
- GitHub: [@nidhi1603](https://github.com/nidhi1603)
- LinkedIn: [linkedin.com/in/nidhirajani](https://linkedin.com/in/nidhirajani)

## Timeline

**Target Completion:** 6-7 weeks
**Daily Commitment:** 3-4 hours
**Documentation:** Updated continuously

---

*This project is part of my portfolio demonstrating real-world data engineering and machine learning skills.*
```
